{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9zgiffYVcu7",
        "outputId": "17bd69e0-9dea-4cba-febd-13a140f339e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.84)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.28.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHvATrgoF5FA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import http.client\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import traceback\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "year1 = 'Mar-2022'\n",
        "year2 = 'Mar-2021'\n",
        "year3 = 'Mar-2020'\n",
        "year4 = 'Mar-2019'\n",
        "\n",
        "#These below categories are analysed \n",
        "LargeCapMar2022 = {}\n",
        "MidCapMar2022 = {}\n",
        "SmallCapMar2022 = {}\n",
        "\n",
        "LargeCapMar2021 = {}\n",
        "MidCapMar2021 = {}\n",
        "SmallCapMar2021 = {}\n",
        "\n",
        "LargeCapMar2020 = {}\n",
        "MidCapMar2020 = {}\n",
        "SmallCapMar2020 = {}\n",
        "\n",
        "LargeCapMar2019 = {}\n",
        "MidCapMar2019 = {}\n",
        "SmallCapMar2019 = {}\n",
        "\n",
        "\n",
        "# We have picked up the 30 stocks listed in NSE index and chosen based on their top marketcap. The details are mentioned on the Google Sheet \n",
        "\n",
        "\n",
        "largeCapStocks = ['BAJAJ-AUTO.NS',\t'TATASTEEL.NS',\t'ICICIBANK.NS',\t'HINDALCO.NS',\t'ONGC.NS',\t'BRITANNIA.NS',\t'MARUTI.NS',\t\n",
        "          'INDUSINDBK.NS',\t'NESTLEIND.NS',\t'NTPC.NS',\t'COALINDIA.NS',\t'ADANIENT.NS',\t'ITC.NS',\t'WIPRO.NS',\t'TITAN.NS',\n",
        "          'RELIANCE.NS',\t'KOTAKBANK.NS',\t'TCS.NS',\t'HEROMOTOCO.NS',\t'CIPLA.NS']\n",
        "\n",
        "midCapStocks = ['TRIDENT.NS',\t'KPITTECH.NS',\t'AAVAS.NS',\t'ISEC.NS',\t'AJANTPHARM.NS',\t'DCMSHRIRAM.NS',\t'IIFLWAM.NS',\t'BDL.NS',\t'CREDITACC.NS',\t'APTUS.NS',\t'JBCHEPHARM.NS',\n",
        "                'NH.NS',\t'ASAHIINDIA.NS',\t'GODREJIND.NS',\t'RATNAMANI.NS',\t'NUVOCO.NS',\t'HAPPSTMNDS.NS',\t'NIACL.NS',\t'CUB.NS',\t'TTKPRESTIG.NS']\n",
        "\n",
        "\n",
        "smallCapStocks = ['IDBI.NS',\t'METROBRAND.NS',\t'TIMKEN.NS',\t'KPITTECH.NS',\t'APOLLOTYRE.NS',\t'CENTRALBK.NS',\t'CAMPUS.NS',\t'FINEORG.NS',\t\n",
        "                  'IIFL.NS',\t'DCMSHRIRAM.NS',\t'APTUS.NS',\t'CARBORUNIV.NS',\t'IIFLWAM.NS',\t'JBCHEPHARM.NS',\n",
        "                  'ELGIEQUIP.NS',\t'CREDITACC.NS',\t'ASAHIINDIA.NS',\t'IRB.NS',\t'NUVOCO.NS']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scenario Configuration\n",
        "\n",
        "stocks = largeCapStocks\n",
        "scenarioTest = 'LargeCapMar2019'\n",
        "year = year1"
      ],
      "metadata": {
        "id": "V89mhXWfJny7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to hold information for each stock/ticker\n",
        "financial_dir = {}\n",
        "\n",
        "for ticker in stocks:\n",
        "    try:\n",
        "    #getting balance sheet data from yahoo finance for the given ticker\n",
        "        temp_dir = {}\n",
        "        url = 'https://finance.yahoo.com/quote/'+ticker+'/balance-sheet'\n",
        "        headerFake = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
        "        page = requests.get(url,headers=headerFake)\n",
        "        page_content = page.content\n",
        "        #soup = BeautifulSoup(page_content,'html.parser')\n",
        "        soup = BeautifulSoup(page_content, 'html5lib')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"Va(m)\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text()] = soup.find('span', string=row.get_text()).find_next('span').text            \n",
        "        \n",
        "        #getting income statement data from yahoo finance for the given ticker\n",
        "        url = 'https://finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
        "        page = requests.get(url,headers=headerFake)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "           rows = t.find_all(\"div\", {\"class\" : \"Va(m)\"})\n",
        "           for row in rows:\n",
        "             temp_dir[row.get_text()] = soup.find('span', string=row.get_text()).find_next('span').text\n",
        "        \n",
        "        #getting cashflow statement data from yahoo finance for the given ticker\n",
        "        url = 'https://finance.yahoo.com/quote/'+ticker+'/cash-flow?p='+ticker\n",
        "        page = requests.get(url,headers=headerFake)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"Va(m)\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text()] = soup.find('span', string=row.get_text()).find_next('span').text\n",
        "        \n",
        "        #getting key statistics data from yahoo finance for the given ticker\n",
        "        url = 'https://finance.yahoo.com/quote/'+ticker+'/key-statistics?p='+ticker\n",
        "        page = requests.get(url,headers=headerFake)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html5lib')\n",
        "        temp_dir['Market Cap (intra-day)'] = soup.find('span',string='Market Cap (intraday)' ).find_next('td').text\n",
        "        temp_dir['Forward Annual Dividend Yield'] = soup.find('span',string='Forward Annual Dividend Yield').find_next('td').text         \n",
        "\n",
        "        #getting stocks return between two dates\n",
        "          #getting stocks return between two dates\n",
        "        if year == 'Mar-2022':\n",
        "          data1 = yf.download(ticker, start='2022-04-01', end='2022-04-02', progress=False).to_numpy()\n",
        "          data2 = yf.download(ticker, start='2022-10-28', end='2022-10-31', progress=False).to_numpy()\n",
        "          retunYearly = (data2[0,1]-data1[0,1])/data1[0,1]\n",
        "          temp_dir['returns'] = \"{:.1%}\".format(retunYearly)\n",
        "        elif year =='Mar-2021':\n",
        "          data1 = yf.download(ticker, start='2021-04-01', end='2021-04-02', progress=False).to_numpy()\n",
        "          data2 = yf.download(ticker, start='2022-03-30', end='2022-03-31', progress=False).to_numpy()\n",
        "          retunYearly = (data2[0,1]-data1[0,1])/data1[0,1]\n",
        "          temp_dir['returns'] = \"{:.1%}\".format(retunYearly)  \n",
        "        elif year =='Mar-2020':\n",
        "          data1 = yf.download(ticker, start='2020-04-01', end='2020-04-02', progress=False).to_numpy()\n",
        "          data2 = yf.download(ticker, start='2021-03-30', end='2021-03-31', progress=False).to_numpy()\n",
        "          retunYearly = (data2[0,1]-data1[0,1])/data1[0,1]\n",
        "          temp_dir['returns'] = \"{:.1%}\".format(retunYearly) \n",
        "        elif year =='Mar-2019':\n",
        "          data1 = yf.download(ticker, start='2019-04-01', end='2019-04-02', progress=False).to_numpy()\n",
        "          data2 = yf.download(ticker, start='2020-03-30', end='2020-03-31', progress=False).to_numpy()\n",
        "          retunYearly = (data2[0,1]-data1[0,1])/data1[0,1]\n",
        "          temp_dir['returns'] = \"{:.1%}\".format(retunYearly)     \n",
        "\n",
        "        #PPE Value\n",
        "       # ticker_object = yf.Ticker(ticker)\n",
        "       # df = ticker_object.balancesheet\n",
        "       # for i, j in df.iterrows():\n",
        "        #  if(i=='Property Plant Equipment'):\n",
        "        #    temp_dir[i] = j[0];\n",
        "        #combining all extracted information with the corresponding ticker into the dictionary\n",
        "        financial_dir[ticker] = temp_dir\n",
        "        print(\"Data successfully scraped for \", ticker)\n",
        "    except:\n",
        "        print(\"Problem scraping data for \",ticker)\n",
        "print('All data webscraped')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cru-nsggQUfe",
        "outputId": "3e41b3e5-62b1-4731-8292-97f7432d1097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully scraped for  BAJAJ-AUTO.NS\n",
            "Data successfully scraped for  TATASTEEL.NS\n",
            "Data successfully scraped for  ICICIBANK.NS\n",
            "Data successfully scraped for  HINDALCO.NS\n",
            "Data successfully scraped for  ONGC.NS\n",
            "Data successfully scraped for  BRITANNIA.NS\n",
            "Data successfully scraped for  MARUTI.NS\n",
            "Data successfully scraped for  INDUSINDBK.NS\n",
            "Data successfully scraped for  NESTLEIND.NS\n",
            "Data successfully scraped for  NTPC.NS\n",
            "Data successfully scraped for  COALINDIA.NS\n",
            "Data successfully scraped for  ADANIENT.NS\n",
            "Data successfully scraped for  ITC.NS\n",
            "Data successfully scraped for  WIPRO.NS\n",
            "Data successfully scraped for  TITAN.NS\n",
            "Data successfully scraped for  RELIANCE.NS\n",
            "Data successfully scraped for  KOTAKBANK.NS\n",
            "Data successfully scraped for  TCS.NS\n",
            "Data successfully scraped for  HEROMOTOCO.NS\n",
            "Data successfully scraped for  CIPLA.NS\n",
            "All data webscraped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the scraped info to a Dataframe\n",
        "combined_financials = pd.DataFrame(financial_dir)\n",
        "combined_financials.dropna(how='all',axis=1,inplace=True) #dropping columns with all Null values\n",
        "tickers = combined_financials.columns #updating the tickers list based on only those tickers whose values were successfully extracted\n",
        "\n",
        "for ticker in stocks:\n",
        "   try:\n",
        "    combined_financials = combined_financials[~combined_financials[ticker].str.contains(\"[a-z]\").fillna(False)]\n",
        "   except Exception as e:\n",
        "     print(e)"
      ],
      "metadata": {
        "id": "gxdPzEt6QY2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required stats for the magic formula\n",
        "stats = [\"EBITDA\",\n",
        "         \"Reconciled Depreciation\",\n",
        "         \"Market Cap (intra-day)\",\n",
        "         \"Net Income Common Stockholders\",\n",
        "         \"Operating Cash Flow\",\n",
        "         \"Capital Expenditure\",\n",
        "         \"Total Assets\",\n",
        "         \"Total Liabilities Net Minority Interest\",\n",
        "         \"Total Assets\",\n",
        "         \"Total Equity Gross Minority Interest\",\n",
        "         \"Total Debt\",\n",
        "         \"Forward Annual Dividend Yield\",\"returns\"]\n",
        "\n",
        "# Short hands for above to keep things simple\n",
        "indx = [\"EBITDA\",\"D&A\",\"MarketCap\",\"NetIncome\",\"CashFlowOps\",\"Capex\",\"CurrAsset\",\n",
        "        \"CurrLiab\",\"PPE\",\"BookValue\",\"TotDebt\",\"DivYield\",\"returns\"]"
      ],
      "metadata": {
        "id": "KEx6F6OAQdqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats = {}\n",
        "for ticker in stocks:\n",
        "    try:\n",
        "        temp = combined_financials[ticker]\n",
        "        ticker_stats = []\n",
        "        for stat in stats:\n",
        "            ticker_stats.append(temp.loc[stat])\n",
        "        all_stats['{}'.format(ticker)] = ticker_stats\n",
        "    except Exception as e:\n",
        "        print(\"Can't read data for \",ticker)\n"
      ],
      "metadata": {
        "id": "fdA505YMQf0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats_df = pd.DataFrame(all_stats,index=indx)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({',': ''}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'M': 'E+03'}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'B': 'E+06'}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'T': 'E+09'}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'%': 'E-02'}, regex=True)\n",
        "for ticker in all_stats_df.columns:\n",
        "    all_stats_df[ticker] = pd.to_numeric(all_stats_df[ticker].values,errors='coerce')\n",
        "all_stats_df.dropna(axis=1,inplace=True)\n",
        "\n",
        "stocks = all_stats_df.columns"
      ],
      "metadata": {
        "id": "crrIGVpCQh1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats_df\n"
      ],
      "metadata": {
        "id": "sR0t7JToQi0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transpose_df = all_stats_df.transpose()\n",
        "final_stats_df = pd.DataFrame()\n",
        "final_stats_df[\"EBIT\"] = transpose_df[\"EBITDA\"] - transpose_df[\"D&A\"]\n",
        "final_stats_df[\"TEV\"] =  transpose_df[\"MarketCap\"].fillna(0) \\\n",
        "                         +transpose_df[\"TotDebt\"].fillna(0) \\\n",
        "                         -(transpose_df[\"CurrAsset\"].fillna(0)-transpose_df[\"CurrLiab\"].fillna(0))\n",
        "final_stats_df[\"EarningYield\"] =  final_stats_df[\"EBIT\"]/final_stats_df[\"TEV\"]\n",
        "final_stats_df[\"FCFYield\"] = (transpose_df[\"CashFlowOps\"]-transpose_df[\"Capex\"])/transpose_df[\"MarketCap\"]\n",
        "final_stats_df[\"ROC\"]  = (transpose_df[\"EBITDA\"] - transpose_df[\"D&A\"])/(transpose_df[\"PPE\"]+transpose_df[\"CurrAsset\"]-transpose_df[\"CurrLiab\"])\n",
        "final_stats_df[\"BookToMkt\"] = transpose_df[\"BookValue\"]/transpose_df[\"MarketCap\"]\n",
        "final_stats_df[\"DivYield\"] = transpose_df[\"DivYield\"]\n"
      ],
      "metadata": {
        "id": "0aOvVNkiQkwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_stats_val_df = final_stats_df.loc[stocks,:]\n",
        "final_stats_val_df[\"CombRank\"] = final_stats_val_df[\"EarningYield\"].rank(ascending=False,na_option='bottom')+final_stats_val_df[\"ROC\"].rank(ascending=False,na_option='bottom')\n",
        "final_stats_val_df[\"MagicFormulaRank\"] = final_stats_val_df[\"CombRank\"].rank(method='first')\n",
        "value_stocks = final_stats_val_df.sort_values(\"MagicFormulaRank\").iloc[:,[2,4,8]]\n",
        "value_stocks['Returns'] = transpose_df[\"returns\"]\n",
        "\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"Value stocks based on Greenblatt's Magic Formula\")\n",
        "\n",
        "print(value_stocks)\n",
        "value_stocks.plot()\n",
        "if(scenarioTest=='LargeCapMar2022'):\n",
        "  LargeCapMar2022 = value_stocks\n",
        "elif(scenarioTest=='MidCapMar2022'):\n",
        "  MidCapMar2022 = value_stocks\n",
        "elif(scenarioTest=='SmallCapMar2022'):\n",
        "  SmallCapMar2022 = value_stocks\n",
        "elif(scenarioTest=='LargeCapMar2021'):\n",
        "  LargeCapMar2021 = value_stocks\n",
        "elif(scenarioTest=='MidCapMar2021'):\n",
        "  MidCapMar2021 = value_stocks\n",
        "elif(scenarioTest=='SmallCapMar2021'):\n",
        "  SmallCapMar2021 = value_stocks\n",
        "elif(scenarioTest=='LargeCapMar2020'):\n",
        "  LargeCapMar2020 = value_stocks\n",
        "elif(scenarioTest=='MidCapMar2020'):\n",
        "  MidCapMar2020 = value_stocks\n",
        "elif(scenarioTest=='SmallCapMar2020'):\n",
        "  SmallCapMar2020 = value_stocks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ul50GoucQnWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}